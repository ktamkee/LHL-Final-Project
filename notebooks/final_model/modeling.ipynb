{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERVER</th>\n",
       "      <th>BTOP_CHAMP_ID</th>\n",
       "      <th>BTOP_CHAMP_MAST</th>\n",
       "      <th>BTOP_WINS</th>\n",
       "      <th>BTOP_LOSSES</th>\n",
       "      <th>BTOP_LEAGUE_POINTS</th>\n",
       "      <th>BJGL_CHAMP_ID</th>\n",
       "      <th>BJGL_CHAMP_MAST</th>\n",
       "      <th>BJGL_WINS</th>\n",
       "      <th>BJGL_LOSSES</th>\n",
       "      <th>...</th>\n",
       "      <th>BOT_MASTERY_DIFF</th>\n",
       "      <th>SUP_MASTERY_DIFF</th>\n",
       "      <th>AVG_LANE_MASTERY_DIFF</th>\n",
       "      <th>BSUM_TEAM_MASTERY</th>\n",
       "      <th>RSUM_TEAM_MASTERY</th>\n",
       "      <th>TEAM_MASTERY_DIFF</th>\n",
       "      <th>BSUM_LP</th>\n",
       "      <th>RSUM_LP</th>\n",
       "      <th>TEAM_LP_DIFF</th>\n",
       "      <th>WINNER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>150</td>\n",
       "      <td>46397</td>\n",
       "      <td>228.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>246</td>\n",
       "      <td>387356</td>\n",
       "      <td>312.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-32349</td>\n",
       "      <td>-652706</td>\n",
       "      <td>-176674.0</td>\n",
       "      <td>938378</td>\n",
       "      <td>1821748</td>\n",
       "      <td>-883370</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>5374.0</td>\n",
       "      <td>-1174.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>114</td>\n",
       "      <td>1161674</td>\n",
       "      <td>373.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>254</td>\n",
       "      <td>35904</td>\n",
       "      <td>589.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-98171</td>\n",
       "      <td>180680</td>\n",
       "      <td>119971.6</td>\n",
       "      <td>2104539</td>\n",
       "      <td>1504681</td>\n",
       "      <td>599858</td>\n",
       "      <td>5029.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>150</td>\n",
       "      <td>156915</td>\n",
       "      <td>194.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>78</td>\n",
       "      <td>48145</td>\n",
       "      <td>432.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41156</td>\n",
       "      <td>-608402</td>\n",
       "      <td>-113640.8</td>\n",
       "      <td>541122</td>\n",
       "      <td>1109326</td>\n",
       "      <td>-568204</td>\n",
       "      <td>4893.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>79</td>\n",
       "      <td>82980</td>\n",
       "      <td>440.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>80</td>\n",
       "      <td>43375</td>\n",
       "      <td>432.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62141</td>\n",
       "      <td>-6671</td>\n",
       "      <td>-89168.0</td>\n",
       "      <td>651726</td>\n",
       "      <td>1097566</td>\n",
       "      <td>-445840</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>4144.0</td>\n",
       "      <td>-645.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>122</td>\n",
       "      <td>462466</td>\n",
       "      <td>299.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>80</td>\n",
       "      <td>43375</td>\n",
       "      <td>432.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>718297</td>\n",
       "      <td>-156272</td>\n",
       "      <td>-455759.2</td>\n",
       "      <td>1545068</td>\n",
       "      <td>3823864</td>\n",
       "      <td>-2278796</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>3766.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SERVER  BTOP_CHAMP_ID  BTOP_CHAMP_MAST  BTOP_WINS  BTOP_LOSSES  \\\n",
       "0  EUROPE WEST            150            46397      228.0        156.0   \n",
       "1  EUROPE WEST            114          1161674      373.0        340.0   \n",
       "2  EUROPE WEST            150           156915      194.0        149.0   \n",
       "3  EUROPE WEST             79            82980      440.0        408.0   \n",
       "4  EUROPE WEST            122           462466      299.0        253.0   \n",
       "\n",
       "   BTOP_LEAGUE_POINTS  BJGL_CHAMP_ID  BJGL_CHAMP_MAST  BJGL_WINS  BJGL_LOSSES  \\\n",
       "0              1068.0            246           387356      312.0        254.0   \n",
       "1               709.0            254            35904      589.0        538.0   \n",
       "2               837.0             78            48145      432.0        375.0   \n",
       "3               736.0             80            43375      432.0        375.0   \n",
       "4               701.0             80            43375      432.0        375.0   \n",
       "\n",
       "   ...  BOT_MASTERY_DIFF  SUP_MASTERY_DIFF  AVG_LANE_MASTERY_DIFF  \\\n",
       "0  ...            -32349           -652706              -176674.0   \n",
       "1  ...            -98171            180680               119971.6   \n",
       "2  ...             41156           -608402              -113640.8   \n",
       "3  ...             62141             -6671               -89168.0   \n",
       "4  ...            718297           -156272              -455759.2   \n",
       "\n",
       "   BSUM_TEAM_MASTERY  RSUM_TEAM_MASTERY  TEAM_MASTERY_DIFF  BSUM_LP  RSUM_LP  \\\n",
       "0             938378            1821748            -883370   4200.0   5374.0   \n",
       "1            2104539            1504681             599858   5029.0   4204.0   \n",
       "2             541122            1109326            -568204   4893.0   4454.0   \n",
       "3             651726            1097566            -445840   3499.0   4144.0   \n",
       "4            1545068            3823864           -2278796   3810.0   3766.0   \n",
       "\n",
       "   TEAM_LP_DIFF  WINNER  \n",
       "0       -1174.0       1  \n",
       "1         825.0       1  \n",
       "2         439.0       0  \n",
       "3        -645.0       1  \n",
       "4          44.0       0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pgd = pd.read_csv('../../data/final_datasets/pre_game_data_1045.csv')\n",
    "pgd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pgd.drop(columns=['SERVER', 'WINNER'])\n",
    "y = pgd['WINNER']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6679389312977099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=77)\n",
    "rf.fit(X_train, y_train)\n",
    "score = rf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [10, 25, 50, 75, 100],\n",
    "    'max_depth' : [8, 9, 10, 11, 12 ],\n",
    "    'criterion' :['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_split': [1, 2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1125 fits failed out of a total of 3375.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.55428711\n",
      " 0.55426262 0.5837498  0.5670913  0.56963907 0.58104687 0.55937449\n",
      " 0.56585007 0.56199575 0.57089662        nan        nan        nan\n",
      "        nan        nan 0.57971583 0.58743263 0.58236159 0.58241058\n",
      " 0.59897926 0.57971583 0.58743263 0.58236159 0.58241058 0.59897926\n",
      "        nan        nan        nan        nan        nan 0.55680222\n",
      " 0.58110403 0.57474277 0.58368447 0.59643149 0.55680222 0.58110403\n",
      " 0.57474277 0.58368447 0.59643149        nan        nan        nan\n",
      "        nan        nan 0.57724971 0.57217867 0.55818226 0.56967173\n",
      " 0.5696554  0.58621591 0.57610648 0.56842234 0.56200392 0.5785481\n",
      "        nan        nan        nan        nan        nan 0.57470194\n",
      " 0.60418096 0.60420545 0.6003348  0.59776253 0.57470194 0.60418096\n",
      " 0.60420545 0.6003348  0.59776253        nan        nan        nan\n",
      "        nan        nan 0.58872285 0.58753879 0.59516577 0.58629757\n",
      " 0.58879634 0.58872285 0.58753879 0.59516577 0.58629757 0.58879634\n",
      "        nan        nan        nan        nan        nan 0.57729871\n",
      " 0.59131145 0.59134411 0.58244325 0.59267516 0.58491752 0.5926425\n",
      " 0.60285808 0.60413196 0.59906092        nan        nan        nan\n",
      "        nan        nan 0.58873918 0.60281725 0.61556427 0.61435571\n",
      " 0.59771354 0.58873918 0.60281725 0.61556427 0.61435571 0.59771354\n",
      "        nan        nan        nan        nan        nan 0.55547117\n",
      " 0.58879634 0.58759595 0.57355871 0.58370897 0.55547117 0.58879634\n",
      " 0.58759595 0.57355871 0.58370897        nan        nan        nan\n",
      "        nan        nan 0.54147477 0.58498285 0.58877184 0.59008656\n",
      " 0.59647232 0.56065654 0.58244325 0.58241875 0.58497469 0.59394904\n",
      "        nan        nan        nan        nan        nan 0.57851543\n",
      " 0.59522293 0.59140944 0.5888535  0.5952066  0.57851543 0.59522293\n",
      " 0.59140944 0.5888535  0.5952066         nan        nan        nan\n",
      "        nan        nan 0.55813327 0.57858076 0.57858076 0.58621591\n",
      " 0.58241875 0.55813327 0.57858076 0.57858076 0.58621591 0.58241875\n",
      "        nan        nan        nan        nan        nan 0.53640372\n",
      " 0.57086396 0.5811122  0.60156786 0.59008656 0.53891883 0.53383146\n",
      " 0.55815777 0.55815777 0.57350972        nan        nan        nan\n",
      "        nan        nan 0.572195   0.59653764 0.59524743 0.609252\n",
      " 0.60923567 0.572195   0.59653764 0.59524743 0.609252   0.60923567\n",
      "        nan        nan        nan        nan        nan 0.55167402\n",
      " 0.56834885 0.56329414 0.56458435 0.56838151 0.55167402 0.56834885\n",
      " 0.56329414 0.56458435 0.56838151        nan        nan        nan\n",
      "        nan        nan 0.56957374 0.5811122  0.60798628 0.59390821\n",
      " 0.60797812 0.5607137  0.57733137 0.61051772 0.60801894 0.60416463\n",
      "        nan        nan        nan        nan        nan 0.57221133\n",
      " 0.58371713 0.61053405 0.59648865 0.59777887 0.57221133 0.58371713\n",
      " 0.61053405 0.59648865 0.59777887        nan        nan        nan\n",
      "        nan        nan 0.56321248 0.58622407 0.58625674 0.59008656\n",
      " 0.58365997 0.56321248 0.58622407 0.58625674 0.59008656 0.58365997\n",
      "        nan        nan        nan        nan        nan 0.54411236\n",
      " 0.56710763 0.57858893 0.5977462  0.58751429 0.56198759 0.5721705\n",
      " 0.57088845 0.58373346 0.59390005        nan        nan        nan\n",
      "        nan        nan 0.57342806 0.57738037 0.57092928 0.57222767\n",
      " 0.5862649  0.57342806 0.57738037 0.57092928 0.57222767 0.5862649\n",
      "        nan        nan        nan        nan        nan 0.58499102\n",
      " 0.60160869 0.61053405 0.59777887 0.59136861 0.58499102 0.60160869\n",
      " 0.61053405 0.59777887 0.59136861        nan        nan        nan\n",
      "        nan        nan 0.59636616 0.5747836  0.59390005 0.57987098\n",
      " 0.5837008  0.59761555 0.5951821  0.60028581 0.58754695 0.60288257\n",
      "        nan        nan        nan        nan        nan 0.58880451\n",
      " 0.59018455 0.60160052 0.60289891 0.5977707  0.58880451 0.59018455\n",
      " 0.60160052 0.60289891 0.5977707         nan        nan        nan\n",
      "        nan        nan 0.57598399 0.59393271 0.61054222 0.61180794\n",
      " 0.59901192 0.57598399 0.59393271 0.61054222 0.61180794 0.59901192\n",
      "        nan        nan        nan        nan        nan 0.53895966\n",
      " 0.592618   0.58882084 0.5785726  0.5952066  0.56576025 0.592618\n",
      " 0.58241058 0.58883717 0.58883717        nan        nan        nan\n",
      "        nan        nan 0.5696064  0.59135228 0.59903642 0.57095378\n",
      " 0.58755512 0.5696064  0.59135228 0.59903642 0.57095378 0.58755512\n",
      "        nan        nan        nan        nan        nan 0.58617508\n",
      " 0.59902825 0.60155969 0.59901192 0.58748979 0.58617508 0.59902825\n",
      " 0.60155969 0.59901192 0.58748979        nan        nan        nan\n",
      "        nan        nan 0.56571942 0.59390005 0.59015189 0.5863139\n",
      " 0.59651315 0.56702597 0.58502368 0.57989548 0.59270782 0.5952311\n",
      "        nan        nan        nan        nan        nan 0.58488486\n",
      " 0.60283358 0.58374163 0.57350155 0.58876368 0.58488486 0.60283358\n",
      " 0.58374163 0.57350155 0.58876368        nan        nan        nan\n",
      "        nan        nan 0.57352605 0.60161685 0.61450269 0.60035114\n",
      " 0.59897926 0.57352605 0.60161685 0.61450269 0.60035114 0.59897926\n",
      "        nan        nan        nan        nan        nan 0.56957374\n",
      " 0.5811122  0.60798628 0.59390821 0.60797812 0.5607137  0.57733137\n",
      " 0.61051772 0.60801894 0.60416463        nan        nan        nan\n",
      "        nan        nan 0.57221133 0.58371713 0.61053405 0.59648865\n",
      " 0.59777887 0.57221133 0.58371713 0.61053405 0.59648865 0.59777887\n",
      "        nan        nan        nan        nan        nan 0.56321248\n",
      " 0.58622407 0.58625674 0.59008656 0.58365997 0.56321248 0.58622407\n",
      " 0.58625674 0.59008656 0.58365997        nan        nan        nan\n",
      "        nan        nan 0.54411236 0.56710763 0.57858893 0.5977462\n",
      " 0.58751429 0.56198759 0.5721705  0.57088845 0.58373346 0.59390005\n",
      "        nan        nan        nan        nan        nan 0.57342806\n",
      " 0.57738037 0.57092928 0.57222767 0.5862649  0.57342806 0.57738037\n",
      " 0.57092928 0.57222767 0.5862649         nan        nan        nan\n",
      "        nan        nan 0.58499102 0.60160869 0.61053405 0.59777887\n",
      " 0.59136861 0.58499102 0.60160869 0.61053405 0.59777887 0.59136861\n",
      "        nan        nan        nan        nan        nan 0.59636616\n",
      " 0.5747836  0.59390005 0.57987098 0.5837008  0.59761555 0.5951821\n",
      " 0.60028581 0.58754695 0.60288257        nan        nan        nan\n",
      "        nan        nan 0.58880451 0.59018455 0.60160052 0.60289891\n",
      " 0.5977707  0.58880451 0.59018455 0.60160052 0.60289891 0.5977707\n",
      "        nan        nan        nan        nan        nan 0.57598399\n",
      " 0.59393271 0.61054222 0.61180794 0.59901192 0.57598399 0.59393271\n",
      " 0.61054222 0.61180794 0.59901192        nan        nan        nan\n",
      "        nan        nan 0.53895966 0.592618   0.58882084 0.5785726\n",
      " 0.5952066  0.56576025 0.592618   0.58241058 0.58883717 0.58883717\n",
      "        nan        nan        nan        nan        nan 0.5696064\n",
      " 0.59135228 0.59903642 0.57095378 0.58755512 0.5696064  0.59135228\n",
      " 0.59903642 0.57095378 0.58755512        nan        nan        nan\n",
      "        nan        nan 0.58617508 0.59902825 0.60155969 0.59901192\n",
      " 0.58748979 0.58617508 0.59902825 0.60155969 0.59901192 0.58748979\n",
      "        nan        nan        nan        nan        nan 0.56571942\n",
      " 0.59390005 0.59015189 0.5863139  0.59651315 0.56702597 0.58502368\n",
      " 0.57989548 0.59270782 0.5952311         nan        nan        nan\n",
      "        nan        nan 0.58488486 0.60283358 0.58374163 0.57350155\n",
      " 0.58876368 0.58488486 0.60283358 0.58374163 0.57350155 0.58876368\n",
      "        nan        nan        nan        nan        nan 0.57352605\n",
      " 0.60161685 0.61450269 0.60035114 0.59897926 0.57352605 0.60161685\n",
      " 0.61450269 0.60035114 0.59897926]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=77),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [8, 9, 10, 11, 12],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [1, 2, 3],\n",
       "                         &#x27;n_estimators&#x27;: [10, 25, 50, 75, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=77),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [8, 9, 10, 11, 12],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [1, 2, 3],\n",
       "                         &#x27;n_estimators&#x27;: [10, 25, 50, 75, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=77)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=77)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=77),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [8, 9, 10, 11, 12],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [1, 2, 3],\n",
       "                         'n_estimators': [10, 25, 50, 75, 100]})"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "CV_rfc = GridSearchCV(estimator=rf, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5992366412213741"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6155642658827372"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERVER</th>\n",
       "      <th>BTOP_CHAMP_ID</th>\n",
       "      <th>BTOP_CHAMP_MAST</th>\n",
       "      <th>BTOP_WINS</th>\n",
       "      <th>BTOP_LOSSES</th>\n",
       "      <th>BTOP_LEAGUE_POINTS</th>\n",
       "      <th>BJGL_CHAMP_ID</th>\n",
       "      <th>BJGL_CHAMP_MAST</th>\n",
       "      <th>BJGL_WINS</th>\n",
       "      <th>BJGL_LOSSES</th>\n",
       "      <th>...</th>\n",
       "      <th>BOT_MASTERY_DIFF</th>\n",
       "      <th>SUP_MASTERY_DIFF</th>\n",
       "      <th>AVG_LANE_MASTERY_DIFF</th>\n",
       "      <th>BSUM_TEAM_MASTERY</th>\n",
       "      <th>RSUM_TEAM_MASTERY</th>\n",
       "      <th>TEAM_MASTERY_DIFF</th>\n",
       "      <th>BSUM_LP</th>\n",
       "      <th>RSUM_LP</th>\n",
       "      <th>TEAM_LP_DIFF</th>\n",
       "      <th>WINNER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>150</td>\n",
       "      <td>46397</td>\n",
       "      <td>228.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>246</td>\n",
       "      <td>387356</td>\n",
       "      <td>312.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-32349</td>\n",
       "      <td>-652706</td>\n",
       "      <td>-176674.0</td>\n",
       "      <td>938378</td>\n",
       "      <td>1821748</td>\n",
       "      <td>-883370</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>5374.0</td>\n",
       "      <td>-1174.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>114</td>\n",
       "      <td>1161674</td>\n",
       "      <td>373.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>254</td>\n",
       "      <td>35904</td>\n",
       "      <td>589.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-98171</td>\n",
       "      <td>180680</td>\n",
       "      <td>119971.6</td>\n",
       "      <td>2104539</td>\n",
       "      <td>1504681</td>\n",
       "      <td>599858</td>\n",
       "      <td>5029.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>150</td>\n",
       "      <td>156915</td>\n",
       "      <td>194.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>78</td>\n",
       "      <td>48145</td>\n",
       "      <td>432.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41156</td>\n",
       "      <td>-608402</td>\n",
       "      <td>-113640.8</td>\n",
       "      <td>541122</td>\n",
       "      <td>1109326</td>\n",
       "      <td>-568204</td>\n",
       "      <td>4893.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>79</td>\n",
       "      <td>82980</td>\n",
       "      <td>440.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>80</td>\n",
       "      <td>43375</td>\n",
       "      <td>432.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62141</td>\n",
       "      <td>-6671</td>\n",
       "      <td>-89168.0</td>\n",
       "      <td>651726</td>\n",
       "      <td>1097566</td>\n",
       "      <td>-445840</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>4144.0</td>\n",
       "      <td>-645.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUROPE WEST</td>\n",
       "      <td>122</td>\n",
       "      <td>462466</td>\n",
       "      <td>299.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>80</td>\n",
       "      <td>43375</td>\n",
       "      <td>432.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>718297</td>\n",
       "      <td>-156272</td>\n",
       "      <td>-455759.2</td>\n",
       "      <td>1545068</td>\n",
       "      <td>3823864</td>\n",
       "      <td>-2278796</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>3766.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SERVER  BTOP_CHAMP_ID  BTOP_CHAMP_MAST  BTOP_WINS  BTOP_LOSSES  \\\n",
       "0  EUROPE WEST            150            46397      228.0        156.0   \n",
       "1  EUROPE WEST            114          1161674      373.0        340.0   \n",
       "2  EUROPE WEST            150           156915      194.0        149.0   \n",
       "3  EUROPE WEST             79            82980      440.0        408.0   \n",
       "4  EUROPE WEST            122           462466      299.0        253.0   \n",
       "\n",
       "   BTOP_LEAGUE_POINTS  BJGL_CHAMP_ID  BJGL_CHAMP_MAST  BJGL_WINS  BJGL_LOSSES  \\\n",
       "0              1068.0            246           387356      312.0        254.0   \n",
       "1               709.0            254            35904      589.0        538.0   \n",
       "2               837.0             78            48145      432.0        375.0   \n",
       "3               736.0             80            43375      432.0        375.0   \n",
       "4               701.0             80            43375      432.0        375.0   \n",
       "\n",
       "   ...  BOT_MASTERY_DIFF  SUP_MASTERY_DIFF  AVG_LANE_MASTERY_DIFF  \\\n",
       "0  ...            -32349           -652706              -176674.0   \n",
       "1  ...            -98171            180680               119971.6   \n",
       "2  ...             41156           -608402              -113640.8   \n",
       "3  ...             62141             -6671               -89168.0   \n",
       "4  ...            718297           -156272              -455759.2   \n",
       "\n",
       "   BSUM_TEAM_MASTERY  RSUM_TEAM_MASTERY  TEAM_MASTERY_DIFF  BSUM_LP  RSUM_LP  \\\n",
       "0             938378            1821748            -883370   4200.0   5374.0   \n",
       "1            2104539            1504681             599858   5029.0   4204.0   \n",
       "2             541122            1109326            -568204   4893.0   4454.0   \n",
       "3             651726            1097566            -445840   3499.0   4144.0   \n",
       "4            1545068            3823864           -2278796   3810.0   3766.0   \n",
       "\n",
       "   TEAM_LP_DIFF  WINNER  \n",
       "0       -1174.0       1  \n",
       "1         825.0       1  \n",
       "2         439.0       0  \n",
       "3        -645.0       1  \n",
       "4          44.0       0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgd = pd.read_csv('../../data/final_datasets/mid_game_data_1045.csv')\n",
    "mgd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mgd.drop(columns=['SERVER', 'WINNER'])\n",
    "y = mgd['WINNER']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7595419847328244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_mgd = RandomForestClassifier(random_state=25)\n",
    "rf_mgd.fit(X_train, y_train)\n",
    "score = rfmg.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39512f3c2a1741d7f752d45a133d4514127029333ea14bc2f3c6c5e6759b9029"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
